./RNNv2Layer/BidirectionLSTM.py:42: DeprecationWarning: Use addLoop instead.
  rnnV2Layer = network.add_rnn_v2(inputT0, 1, nHidden, nH, trt.RNNOperation.LSTM)  # 基于单输入初始范例代码
./RNNv2Layer/BidirectionLSTM.py:59: DeprecationWarning: Use get_tensor_mode instead.
  nInput = np.sum([engine.binding_is_input(i) for i in range(engine.num_bindings)])
./RNNv2Layer/BidirectionLSTM.py:67: DeprecationWarning: Use get_tensor_shape instead.
  bufferH.append(np.empty(context.get_binding_shape(nInput + i), dtype=trt.nptype(engine.get_binding_dtype(nInput + i))))
./RNNv2Layer/BidirectionLSTM.py:67: DeprecationWarning: Use get_tensor_dtype instead.
  bufferH.append(np.empty(context.get_binding_shape(nInput + i), dtype=trt.nptype(engine.get_binding_dtype(nInput + i))))
Input 0: (3, 4, 7) 
 [[[1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]]

 [[1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]]

 [[1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]
  [1. 1. 1. 1. 1. 1. 1.]]]
Input 1: (3, 1, 5) 
 [[[0. 0. 0. 0. 0.]]

 [[0. 0. 0. 0. 0.]]

 [[0. 0. 0. 0. 0.]]]
Input 2: (3, 1, 5) 
 [[[0. 0. 0. 0. 0.]]

 [[0. 0. 0. 0. 0.]]

 [[0. 0. 0. 0. 0.]]]
Output 0: (1, 3, 4, 10) 
 [[[[0.7605172  0.7605172  0.7605172  0.7605172  0.7605172  0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.9639405  0.9639405  0.9639405  0.9639405  0.9639405  0.9950378  0.9950378  0.9950378  0.9950378  0.9950378 ]
   [0.9950378  0.9950378  0.9950378  0.9950378  0.9950378  0.9639405  0.9639405  0.9639405  0.9639405  0.9639405 ]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164 0.7605172  0.7605172  0.7605172  0.7605172  0.7605172 ]]

  [[0.7605172  0.7605172  0.7605172  0.7605172  0.7605172  0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.9639405  0.9639405  0.9639405  0.9639405  0.9639405  0.9950378  0.9950378  0.9950378  0.9950378  0.9950378 ]
   [0.9950378  0.9950378  0.9950378  0.9950378  0.9950378  0.9639405  0.9639405  0.9639405  0.9639405  0.9639405 ]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164 0.7605172  0.7605172  0.7605172  0.7605172  0.7605172 ]]

  [[0.7605172  0.7605172  0.7605172  0.7605172  0.7605172  0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.9639405  0.9639405  0.9639405  0.9639405  0.9639405  0.9950378  0.9950378  0.9950378  0.9950378  0.9950378 ]
   [0.9950378  0.9950378  0.9950378  0.9950378  0.9950378  0.9639405  0.9639405  0.9639405  0.9639405  0.9639405 ]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164 0.7605172  0.7605172  0.7605172  0.7605172  0.7605172 ]]]]
Output 1: (1, 3, 2, 5) 
 [[[[0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]]

  [[0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]]

  [[0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]
   [0.99932164 0.99932164 0.99932164 0.99932164 0.99932164]]]]
Output 2: (1, 3, 2, 5) 
 [[[[3.998999 3.998999 3.998999 3.998999 3.998999]
   [3.998999 3.998999 3.998999 3.998999 3.998999]]

  [[3.998999 3.998999 3.998999 3.998999 3.998999]
   [3.998999 3.998999 3.998999 3.998999 3.998999]]

  [[3.998999 3.998999 3.998999 3.998999 3.998999]
   [3.998999 3.998999 3.998999 3.998999 3.998999]]]]
